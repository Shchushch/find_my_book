import streamlit as st
import pandas as pd
import random as rd
import webbrowser as wb
import numpy as np
from find import find_similar,df,lems_eng,lems_rus,clean,find_unsimilar

st.set_page_config(
    page_title="–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –∫–Ω–∏–≥",
    page_icon="üìñ",
    layout="wide",
    #initial_sidebar_state="expanded"
)
with st.expander('–ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º'):
    if st.checkbox('–° –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π'):
        df
    else:
        df.iloc[:,:-1]
st.title('–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –∫–Ω–∏–≥')
#negability= st.checkbox('–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º—Ç (beta)')
with st.form(key='search_form'):
    
    input=st.text_input('–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å','–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞')

    # if negability:
    #     neg=st.text_input('–í–≤–µ–¥–∏—Ç–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å')


    search_but=st.form_submit_button('–ò—Å–∫–∞—Ç—å')

items_per_page=st.number_input('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–∏–≥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ',min_value=1,max_value=10,value=5)
# if search_but:
#     st.session_state.clicked = True
#st.toast('–£—Ñ—Ñ')
#@st.cache_data(experimental_allow_widgets=True)
def books_show(books_idx,sim,n=items_per_page):
    col=[]
    books=df.copy().iloc[books_idx][:n]
    for author in books['author']:
        if author.find('–î–æ–Ω—Ü–æ–≤–∞')!=-1:
            #st.toast('–£—Ñ—Ñ')
            pass
    books['sims']=sims[:n]
    with st.expander('–î–∞—Ç–∞—Ñ—Ä–µ–π–º —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏'):
        books
    #print(books.index)
    for i,book_id in enumerate(books_idx[:n]):
        pic_col,text_col=st.columns([0.2,0.8])
        '---'
        
        url=books.loc[book_id][0]
        #url
        pic_col.image(books.loc[book_id,'image_url'],use_column_width=True)
        pic_col.markdown(f'<a href={url} target="_blank">–°—Å—ã–ª–∫–∞ –Ω–∞ –∫–Ω–∏–≥—É</a>', unsafe_allow_html=True)
        pic_col.markdown(f'**–°—Ç–µ–ø–µ–Ω—å –ø–æ—Ö–æ–∂–µ—Å—Ç–∏:** {books.loc[book_id,"sims"]:.4f}')

        #col[i][0].button('–ö—É–ø–∏—Ç—å',key=books['page_url'][i],on_click=lambda: wb.open_new_tab(books['page_url'][i]))

        text_col.markdown('## ' + books.loc[book_id, 'title'])
        text_col.markdown('**–ê–≤—Ç–æ—Ä:** ' + books.loc[book_id, 'author'])
        text_col.markdown('**–ñ–∞–Ω—Ä:** ' + books.loc[book_id, 'genre'])
        text_col.markdown('**–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è:** ' + books.loc[book_id, 'annotation'])
  
if search_but:
    neg_mark=input.find(' -')
    cleaned_input=clean(lems_eng(lems_rus(input[:neg_mark])))
    cleaned_neg=clean(lems_eng(lems_rus(input[neg_mark+2:])))
    #print(cleaned_neg.split(),df.loc[15390,'lemmatized'].split())
    with st.spinner('Wait for it...'):
        if neg_mark!=-1:
            st.markdown(f'**–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å:** {cleaned_input} \n\n **–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å:** {cleaned_neg}')
            sims,books_idx=find_similar(cleaned_input,50)
            for book in books_idx:
                if any(word in cleaned_neg.split() for word in df.loc[book,'lemmatized'].split()):
                    books_idx=np.delete(books_idx,np.where(books_idx==book))        
        else:
            st.markdown(f'**–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å:** {cleaned_input}')
            sims,books_idx=find_similar(cleaned_input)
        print(f'–ü–æ—Ö–æ–∂–µ—Å—Ç–∏:\n{sims}\n–ò–Ω–¥–µ–∫—Å—ã:\n{books_idx}')
        books_show(books_idx,sims)
